import tempfile
import time
import random
from pathlib import Path

from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from playwright.sync_api import sync_playwright
from pymongo.errors import DuplicateKeyError
from selenium.webdriver.common.by import By
from pymongo import MongoClient
from selenium import webdriver


class ProxyManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–º –ø—Ä–æ–∫—Å–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π"""
    
    def __init__(self, proxy_file: str = "proxies.txt"):
        self.proxy_file = proxy_file
        self.proxies = []
        self.current_index = 0
        self.load_proxies()
    
    def load_proxies(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.proxy_file, 'r') as f:
                self.proxies = [
                    line.strip() 
                    for line in f 
                    if line.strip() and not line.strip().startswith('#')
                ]
            if self.proxies:
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.proxies)} –ø—Ä–æ–∫—Å–∏")
            else:
                print("‚ö†Ô∏è –§–∞–π–ª –ø—Ä–æ–∫—Å–∏ –ø—É—Å—Ç, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
        except FileNotFoundError:
            print(f"‚ö†Ô∏è –§–∞–π–ª {self.proxy_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
    
    def get_next_proxy(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏ (—Ä–æ—Ç–∞—Ü–∏—è –ø–æ –∫—Ä—É–≥—É)"""
        if not self.proxies:
            return None
        
        proxy = self.proxies[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.proxies)
        return proxy
    
    def get_random_proxy(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏"""
        if not self.proxies:
            return None
        return random.choice(self.proxies)


class MongoInterface:
    def __init__(self, connection_uri: str, database: str = "farfetch_db"):
        self._client = MongoClient(connection_uri)
        self._database = self._client[database]

    def create_collection(self, collection_name: str):
        if collection_name in self._database.list_collection_names():
            raise Exception(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")    
        
        collection = self._database[collection_name]
        collection.create_index("url", unique=True)

    def insert_data(self, collection_name, data_sample):
        collection = self._database[collection_name]
        try:
            collection.insert_one(data_sample)
        except DuplicateKeyError as exc:
            print(f"URL: {data_sample['url']} —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∞–∑—É")


class WebDriverInterface:
    def __init__(self, page_loading_time: int = 3):
        chrome_options = Options()
        chrome_options.binary_location = "/usr/bin/chromium-browser"
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")

        temp_dir = tempfile.mkdtemp()
        chrome_options.add_argument(f"--user-data-dir={temp_dir}")

        self.driver = webdriver.Chrome(service=Service("/usr/bin/chromedriver"), options=chrome_options)
        self._page_loading_time = page_loading_time

    def get_number_of_pages(self, url: str):
        self.driver.get(url)
        time.sleep(self._page_loading_time)
        element = self.driver.find_element(By.XPATH, '//*[@data-component="PaginationLabel"]')
        if element:
            return int(element.text.split(" –∏–∑ ")[1])
        return 0

    def get_elements(self, url: str):
        self.driver.get(url=url)
        time.sleep(self._page_loading_time)
        catalog = self.driver.find_element(By.ID, 'catalog-grid')
        elements = catalog.find_elements(By.XPATH, './/*[@data-component="ProductCardLink"]')
        if elements:
            return [x.get_attribute("href") for x in elements]
        return []

    def parse_elements(self, links, category, gender):
        data = []
        for link in links[:10]:
            self.driver.get(link)
            time.sleep(self._page_loading_time)
            try:
                page = self.driver.find_element(By.ID, 'content')
            except Exception as exc:
                print(f"Content parsing error in {link}")
                continue

            images = [x.get_attribute("src") for x in page.find_elements(By.XPATH, './/*[@data-component="Img"]')]
            try:
                price = page.find_element(By.XPATH, './/*[@data-component="PriceLarge"]').text
            except Exception as exc:
                print(f"Price parsing error in {link}")
                price = None
            
            try:
                short_description = page.find_element(By.XPATH, './/*[@data-component="Body"][@data-testid="product-short-description"]').text
            except Exception as exc:
                print(f"Short description parsing error in {link}")
                short_description = None

            data.append({
                "url": link,
                "images": images,
                "price": price,
                "short_description": short_description,
                "category": category,
                "gender": gender
            })

        return data


import time
from playwright.sync_api import sync_playwright

class PlaywrightInterface:
    def __init__(self, page_loading_time: int = 3, headless: bool = True, use_proxy: bool = True):
        self.page_loading_time = page_loading_time
        self.playwright = sync_playwright().start()
        self.proxy_manager = ProxyManager() if use_proxy else None
        self.use_proxy = use_proxy
        self.current_proxy = None
        self.failed_proxies = set()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –ø–µ—Ä–≤—ã–º –ø—Ä–æ–∫—Å–∏
        self._init_browser(headless)

    def _init_browser(self, headless: bool = True):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ —Å –ø—Ä–æ–∫—Å–∏"""
        proxy_config = None
        
        if self.proxy_manager:
            proxy_url = self._get_working_proxy()
            if proxy_url:
                self.current_proxy = proxy_url
                # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–∫—Å–∏ URL
                if '@' in proxy_url:
                    # –§–æ—Ä–º–∞—Ç: protocol://username:password@host:port
                    protocol = proxy_url.split('://')[0]
                    creds_and_host = proxy_url.split('://')[1]
                    creds = creds_and_host.split('@')[0]
                    host = creds_and_host.split('@')[1]
                    username, password = creds.split(':')
                    
                    proxy_config = {
                        "server": f"{protocol}://{host}",
                        "username": username,
                        "password": password
                    }
                else:
                    # –§–æ—Ä–º–∞—Ç: protocol://host:port
                    # –ü—Ä–æ–±—É–µ–º –∑–∞–º–µ–Ω–∏—Ç—å http –Ω–∞ https –¥–ª—è https-—Å–∞–π—Ç–æ–≤
                    if proxy_url.startswith('http://'):
                        proxy_config = {"server": proxy_url}
                    else:
                        proxy_config = {"server": proxy_url}
                
                print(f"üîê –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {proxy_config.get('server')}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –ø—Ä–æ–∫—Å–∏
        if hasattr(self, 'browser') and self.browser:
            self.browser.close()
            
        self.browser = self.playwright.chromium.launch(
            headless=headless,
            proxy=proxy_config
        )
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä
        self.page = self.browser.new_page(user_agent=(
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0.0.0 Safari/537.36"
        ))

        # –¢–∞–π–º–∞—É—Ç—ã
        self.page.set_default_timeout(30000)
        self.page.set_default_navigation_timeout(60000)
    
    def _get_working_proxy(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏, –ø—Ä–æ–ø—É—Å–∫–∞—è –Ω–µ—É–¥–∞—á–Ω—ã–µ"""
        if not self.proxy_manager or not self.proxy_manager.proxies:
            return None
        
        attempts = 0
        max_attempts = len(self.proxy_manager.proxies)
        
        while attempts < max_attempts:
            proxy = self.proxy_manager.get_next_proxy()
            if proxy not in self.failed_proxies:
                return proxy
            attempts += 1
        
        # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–∫—Å–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å, –æ—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ—É–¥–∞—á –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
        print("‚ö†Ô∏è –í—Å–µ –ø—Ä–æ–∫—Å–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞...")
        self.failed_proxies.clear()
        return self.proxy_manager.get_next_proxy()
    
    def _switch_proxy(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏"""
        if not self.use_proxy or not self.proxy_manager:
            return False
        
        if self.current_proxy:
            self.failed_proxies.add(self.current_proxy)
            print(f"‚ùå –ü—Ä–æ–∫—Å–∏ {self.current_proxy} –¥–æ–±–∞–≤–ª–µ–Ω –≤ —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫")
        
        print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –Ω–æ–≤—ã–π –ø—Ä–æ–∫—Å–∏...")
        self._init_browser()
        return True

    def safe_goto(self, url, add_delay=True):
        """–ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å retry –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –±–∞–Ω–Ω–µ—Ä–æ–≤"""
        # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º (–ø—Ä–æ—Ç–∏–≤ rate limiting)
        # –¢–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞, –Ω–µ –¥–ª—è –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤
        if add_delay and "items.aspx" in url:
            delay = random.uniform(1, 2)  # 1-2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞
            print(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f}s –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º...")
            time.sleep(delay)
        
        max_retries = 3
        proxy_switched = False
        
        for attempt in range(max_retries):
            try:
                response = self.page.goto(url, wait_until="domcontentloaded", timeout=60000)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
                if response and response.status == 429:
                    print(f"üö´ Rate limit (429)!")
                    # –ü—Ä–∏ 429 –ø—Ä–æ–±—É–µ–º —Å–º–µ–Ω–∏—Ç—å –ø—Ä–æ–∫—Å–∏
                    if not proxy_switched and self._switch_proxy():
                        proxy_switched = True
                        print("üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏...")
                        continue
                    else:
                        print(f"‚è±Ô∏è –ñ–¥–µ–º 60 —Å–µ–∫—É–Ω–¥...")
                        time.sleep(60)
                        return False
                elif response and response.status >= 400:
                    print(f"‚ö†Ô∏è HTTP –æ—à–∏–±–∫–∞ {response.status}")
                    # –ü—Ä–∏ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–∫–∞—Ö —Ç–æ–∂–µ –ø—Ä–æ–±—É–µ–º —Å–º–µ–Ω–∏—Ç—å –ø—Ä–æ–∫—Å–∏
                    if not proxy_switched and self._switch_proxy():
                        proxy_switched = True
                        print("üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏...")
                        continue
                    return False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –ø—Ä–æ–∏–∑–æ—à–µ–ª —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ –≥–ª–∞–≤–Ω—É—é –∏–ª–∏ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                current_url = self.page.url
                if "items.aspx" not in current_url and "page=" in url:
                    print(f"‚ö†Ô∏è –†–µ–¥–∏—Ä–µ–∫—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {current_url}")
                    return False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –ø—É—Å—Ç–∞—è –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç
                self.page.wait_for_selector(
                    '[data-component="PriceCallout"], [data-testid="productCard"], [data-component="PaginationLabel"]',
                    timeout=15000  # –£–º–µ–Ω—å—à–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                )

                # –ó–∞–∫—Ä—ã–≤–∞–µ–º pop-up / –∫—É–∫–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
                if attempt == 0:
                    for btn_text in ["Accept All", "Continue", "–ü—Ä–∏–Ω—è—Ç—å"]:
                        try:
                            self.page.locator(f'button:has-text("{btn_text}")').click(timeout=2000)
                        except:
                            pass

                return True
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries} –Ω–µ —É–¥–∞–ª–∞—Å—å: {type(e).__name__}")
                
                # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–æ–±—É–µ–º —Å–º–µ–Ω–∏—Ç—å –ø—Ä–æ–∫—Å–∏
                if not proxy_switched and ('TimeoutError' in str(type(e)) or 'NetworkError' in str(type(e))):
                    if self._switch_proxy():
                        proxy_switched = True
                        print("üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏...")
                        continue
                
                if attempt < max_retries - 1:
                    time.sleep(3 * (attempt + 1))  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É —Å –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                else:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å: {type(e).__name__}")
        return False

    def get_number_of_pages(self, url: str):
        if not self.safe_goto(url):
            return 0
        try:
            element = self.page.locator('[data-component="PaginationLabel"]').first
            text = element.text_content()
            if text:
                return int(text.split(" –∏–∑ ")[1])
        except Exception:
            return 0
        return 0

    def get_elements(self, url: str):
        if not self.safe_goto(url):
            return []
        try:
            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞
            self.page.wait_for_selector('#catalog-grid', timeout=10000)
            catalog_links = self.page.locator('#catalog-grid [data-component="ProductCardLink"]')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤
            count = catalog_links.count()
            if count == 0:
                print(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–≤–∞—Ä–æ–≤")
                return []
            
            hrefs = catalog_links.evaluate_all("els => els.map(e => e.href)")
            print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(hrefs)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            return hrefs or []
        except Exception as exc:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Å—ã–ª–æ–∫: {type(exc).__name__}")
            return []

    def parse_elements(self, links, category, gender):
        data = []
        for i, link in enumerate(links):
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏ (0.5-1 —Å–µ–∫)
            if i > 0:
                import random
                time.sleep(random.uniform(0.5, 1))
            
            if not self.safe_goto(link, add_delay=False):
                continue
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                images = self.page.locator('[data-component="Img"]').evaluate_all(
                    "els => els.map(e => e.src)"
                )

                # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–∞—Ö
                price_selector = (
                    '[data-component="PriceLarge"], '
                    '[data-component="PriceFinal"], '
                    '[data-component="PriceOriginal"], '
                    '[data-component="PriceWithSchema"], '
                    '[itemprop="price"]'
                )
                try:
                    self.page.wait_for_selector(price_selector, timeout=30000)
                    price = self.page.locator(price_selector).first.text_content()
                except:
                    print(f"‚ö†Ô∏è –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ {link}")
                    price = None

                # –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                try:
                    short_description = self.page.locator(
                        '[data-component="Body"][data-testid="product-short-description"]'
                    ).first.text_content()
                except:
                    short_description = None

                data.append({
                    "url": link,
                    "images": images,
                    "price": price,
                    "short_description": short_description,
                    "category": category,
                    "gender": gender
                })
            except Exception as exc:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {link}: {exc}")
                continue

        return data

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞ –∏ Playwright"""
        self.browser.close()
        self.playwright.stop()
